{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matlab-stuff  kaggle-house \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LassoCV, LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from xgboost.sklearn import XGBRegressor        \n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# save shape for splitting later\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation function\n",
    "n_folds = 5\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a heatmap of the features\n",
    "corr = train.corr()\n",
    "#plt.subplots(figsize=(20, 20))\n",
    "#sns.heatmap(corr, cmap='rainbow', vmax=0.9, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Now concatenate the training and test data so we can fill in missing variables\n",
    "y_train = train.SalePrice.values\n",
    "allData = pd.concat((train, test)).reset_index(drop=True)\n",
    "allData.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "all_data_na = (allData.isnull().sum() / len(allData)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\n",
    "\n",
    "missingDataPlot = pd.DataFrame({'Missing Ratio' : all_data_na})\n",
    "#missingDataPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in any NA values with \"None\" where it applies\n",
    "allData['PoolQC'] = allData['PoolQC'].fillna(\"None\")\n",
    "allData['MiscFeature'] = allData['MiscFeature'].fillna(\"None\")\n",
    "allData['Alley'] = allData['Alley'].fillna(\"None\")\n",
    "allData['Fence'] = allData['Fence'].fillna(\"None\")\n",
    "allData['FireplaceQu'] = allData['FireplaceQu'].fillna(\"None\")\n",
    "allData['BsmtExposure'] = allData['BsmtExposure'].fillna(\"None\")\n",
    "allData['BsmtCond'] = allData['BsmtCond'].fillna(\"None\")\n",
    "allData['BsmtQual'] = allData['BsmtQual'].fillna(\"None\")\n",
    "allData['BsmtFinType1'] = allData['BsmtFinType1'].fillna(\"None\")\n",
    "allData['BsmtFinType2'] = allData['BsmtFinType2'].fillna(\"None\")\n",
    "\n",
    "# Is this the best way to handle this (in this case, None = None)\n",
    "allData['MasVnrType'] = allData['MasVnrType'].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoning is mixed type (objects etc). by forcing str, the fillna works again\n",
    "allData['MSZoning']=allData['MSZoning'].astype(str)\n",
    "allData['KitchenQual']=allData['KitchenQual'].astype(str)\n",
    "allData['Exterior1st']=allData['Exterior1st'].astype(str)\n",
    "allData['Exterior2nd']=allData['Exterior2nd'].astype(str)\n",
    "allData['Electrical']=allData['Electrical'].astype(str)\n",
    "# mszoning has a special \"nan\" that is not np.nan\n",
    "# allData['MSZoning'] = allData['MSZoning'].replace({\"nan\" : allData['MSZoning'].mode()},regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other features will require numerical data\n",
    "allData['GarageCars'] = allData['GarageCars'].fillna(0)\n",
    "allData['BsmtFullBath'] = allData['BsmtFullBath'].fillna(0)\n",
    "allData['BsmtHalfBath'] = allData['BsmtHalfBath'].fillna(0)\n",
    "allData['BsmtUnfSF'] = allData['BsmtUnfSF'].fillna(0)\n",
    "allData['TotalBsmtSF'] = allData['TotalBsmtSF'].fillna(0)\n",
    "allData['BsmtFinSF1'] = allData['TotalBsmtSF'].fillna(0)\n",
    "allData['BsmtFinSF2'] = allData['TotalBsmtSF'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features that may skew data if their missing data is filled with 0 or None\n",
    "allData.drop(['GarageArea'], axis=1, inplace=True)\n",
    "allData.drop(['GarageYrBlt'], axis=1, inplace=True)\n",
    "allData.drop(['GarageQual'], axis=1, inplace=True)\n",
    "allData.drop(['GarageCond'], axis=1, inplace=True)\n",
    "allData.drop(['GarageFinish'], axis=1, inplace=True)\n",
    "allData.drop(['GarageType'], axis=1, inplace=True)\n",
    "allData.drop(['MasVnrArea'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special Cases: LotFrontage, MSZoning, Utilities, Electrical, Exterior1st, Exterior2nd, Functional\n",
    "# For the following features, it may be safe to asusme that there is consistency within\n",
    "# the neighborhood. We can fill with a value based on the other houses in that neighborhood\n",
    "allData['LotFrontage'] = allData.groupby(\"Neighborhood\")['LotFrontage'].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "\n",
    "# TODO\n",
    "# Should this be mode of neighborhood?\n",
    "# Need to make sure that we are not filling in a nan value with nan\n",
    "allData['MSZoning'] = allData.groupby(\"Neighborhood\")['MSZoning'].transform(\n",
    "    lambda x: x.replace(\"nan\", x.mode()[0]))\n",
    "\n",
    "\n",
    "allData['Exterior2nd'] = allData.groupby(\"Neighborhood\")['Exterior2nd'].transform(\n",
    "    lambda x: x.replace(\"nan\", \"woogiewoogie\"))\n",
    "\n",
    "allData['Exterior1st'] = allData.groupby(\"Neighborhood\")['Exterior1st'].transform(\n",
    "    lambda x: x.replace(\"nan\", \"woogiewoogie\"))\n",
    "\n",
    "# allData['MSZoning'] = allData['MSZoning'].fillna(allData['MSZoning'].mode())\n",
    "\n",
    "# TODO\n",
    "# Should this be by year or neighborhood?\n",
    "allData['Electrical'] = allData.groupby(\"Neighborhood\")['Electrical'].transform(\n",
    "    lambda x: x.fillna(x.mode()))\n",
    "\n",
    "# TODO\n",
    "# Should these be mode of neighborhood?\n",
    "allData['Exterior1st'] = allData.groupby(\"Neighborhood\")['Exterior1st'].transform(\n",
    "    lambda x: x.fillna(x.mode()))\n",
    "allData['Exterior2nd'] = allData.groupby(\"Neighborhood\")['Exterior2nd'].transform(\n",
    "    lambda x: x.fillna(x.mode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data description states to assume  Typical funtionality unless otherwise stated\n",
    "allData['Functional'] = allData['Functional'].fillna(\"Typ\")\n",
    "\n",
    "# In data description, WD == Warranty Deed - Conventional\n",
    "allData['SaleType'] = allData['SaleType'].fillna(\"WD\")\n",
    "\n",
    "# For Utilities, the vast majority of the houses have the same value.\n",
    "missingDataPlot = [x for x in allData['Utilities'] if x != \"AllPub\"]\n",
    "#missingDataPlot\n",
    "\n",
    "# Only three of these houses do not have \"AllPub.\" \n",
    "# The \"NoSeWa\" is in the training set. \n",
    "# The feature is therefore useless to us for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Do we also drop the house that has NoSeWa?\n",
    "allData.drop(['Utilities'], axis=1, inplace=True)\n",
    "\n",
    "# Check one more time to make sure we have not missed any missing data\n",
    "nan_rows = allData[allData.isnull().T.any().T]\n",
    "#nan_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_na = (allData.isnull().sum() / len(allData)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\n",
    "\n",
    "missingDataPlot = pd.DataFrame({'Missing Ratio' : all_data_na})\n",
    "#missingDataPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change 'secretly ordinal' features into numerical ones, provide more data to the model\n",
    "has_rank = [col for col in allData if 'TA' in list(allData[col])]\n",
    "dic_num = {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n",
    "allData['MSSubClass'] = allData['MSSubClass'].astype('category')\n",
    "\n",
    "for col in has_rank:\n",
    "    allData[col+'_2num'] = allData[col].map(dic_num)\n",
    "\n",
    "allData = pd.get_dummies(allData)\n",
    "d_cols = allData.select_dtypes(include=['number']).columns\n",
    "allData = allData[d_cols]\n",
    "allData = allData.fillna(allData.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify skew for numerical features\n",
    "cols = [col for col in allData if '_2num' in col or '_' not in col]\n",
    "skew = [abs(stats.skew(allData[col])) for col in allData if '_2num' in col or '_' not in col]\n",
    "skews = pd.DataFrame()\n",
    "skews['Columns'] = cols\n",
    "skews['Skew_Magnintudes'] = skew\n",
    "cols_unskew = skews[skews.Skew_Magnintudes > 1].Columns\n",
    "allData_unskew = allData.copy()\n",
    "\n",
    "# replace with log(n+1)\n",
    "for col in cols_unskew:\n",
    "    allData_unskew[col] = np.log1p(allData[col])\n",
    "\n",
    "# unskew SalePrice\n",
    "y_train_unskew = np.log1p(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of annoying warning that we thought was an error\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# Split the testing and training data back into two collections\n",
    "train = allData_unskew.query(\"Id < 1461\")\n",
    "train['SalePrice'] = y_train_unskew\n",
    "test = allData_unskew.query(\"Id >= 1461\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\Anaconda3\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:323: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return  self.results.resid / sigma / np.sqrt(1 - hii)\n",
      "C:\\Users\\matth\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\matth\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\matth\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "C:\\Users\\matth\\Anaconda3\\lib\\site-packages\\statsmodels\\stats\\multitest.py:147: RuntimeWarning: invalid value encountered in less_equal\n",
      "  reject = pvals <= alphacBonf\n",
      "C:\\Users\\matth\\Anaconda3\\lib\\site-packages\\statsmodels\\stats\\multitest.py:251: RuntimeWarning: invalid value encountered in greater\n",
      "  pvals_corrected[pvals_corrected>1] = 1\n"
     ]
    }
   ],
   "source": [
    "# identify outliers (SLOW)\n",
    "X = train.drop(['SalePrice','Id'], axis = 1)\n",
    "model = sm.OLS(y_train_unskew,X)\n",
    "results = model.fit()\n",
    "bonf_test = results.outlier_test()['bonf(p)']\n",
    "bonf_outlier = list(bonf_test[bonf_test<1e-3].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers from training data\n",
    "train_good = train.drop(bonf_outlier, axis=0)\n",
    "y_train_good = np.delete(y_train_unskew, bonf_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- EXPORT CLEAN DATA ----------\n",
    "\n",
    "# Then write the data sets to a csv\n",
    "train_good.to_csv('p_train.csv')\n",
    "test.to_csv('p_test.csv')\n",
    "\n",
    "# check Id nums\n",
    "#file = pd.read_csv('p_test.csv')\n",
    "#file[\"Id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- LINEAR REGRESSION ----------\n",
    "\n",
    "x_train = train_good.drop(['SalePrice', 'Id'], axis=1)\n",
    "x_test  = test.drop(['Id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "rf_test = RandomForestRegressor(max_depth=30, n_estimators=500, max_features=100, oob_score=True, random_state=1234)\n",
    "rf_test.fit(x_train, y_train_good)\n",
    "preds_rf = np.expm1(rf_test.predict(x_test))    # expm1 (inv of logp1) un-normalizes the dependent variable SalePrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB regressor\n",
    "xgb_test = XGBRegressor(learning_rate=0.05, n_estimators=500, max_depth=3, colsample_bytree=0.2)\n",
    "xgb_test.fit(x_train, y_train_good)\n",
    "preds_xgb = np.expm1(xgb_test.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LassoCV\n",
    "scaler = StandardScaler()\n",
    "LCV = LassoCV()\n",
    "scale_LCV = Pipeline([('scaler', scaler), ('LCV', LCV)])\n",
    "scale_LCV.fit(x_train, y_train_good)\n",
    "preds_lasso = np.expm1(scale_LCV.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enet\n",
    "#scaler = RobustScaler()\n",
    "en = ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3)\n",
    "en.fit(x_train,y_train_good)\n",
    "preds_en = np.expm1(en.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37789639139.86572\n",
      "37741625532.37645\n",
      "38379511375.63684\n",
      "37955455719.60956\n"
     ]
    }
   ],
   "source": [
    "# get mean squared error\n",
    "\n",
    "\n",
    "train_lasso = np.expm1(scale_LCV.predict(x_train))\n",
    "train_xgb = np.expm1(xgb_test.predict(x_train))\n",
    "train_en  = np.expm1(en.predict(x_train))\n",
    "\n",
    "l_error = mean_squared_error(y_train_good, train_lasso)\n",
    "x_error = mean_squared_error(y_train_good, train_xgb)\n",
    "trains = (train_xgb*3 +train_lasso*5)/8\n",
    "all_error = mean_squared_error(y_train_good, trains)\n",
    "en_error = mean_squared_error(y_train_good,train_en)\n",
    "\n",
    "print(en_error)\n",
    "print(l_error)\n",
    "print(x_error)\n",
    "print(all_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup a metamodel for the various predictions\n",
    "metas = pd.DataFrame()\n",
    "metas['XGB'] = train_xgb\n",
    "metas['Lasso'] = train_lasso\n",
    "metas['EN'] = train_en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use lasso to find meta model weights\n",
    "\n",
    "# LassoCV\n",
    "scaler = StandardScaler()\n",
    "META_LCV = LinearRegression()\n",
    "meta_model = Pipeline([('scaler', scaler), ('LCV', META_LCV)])\n",
    "meta_model.fit(metas, y_train_good)\n",
    "meta_train = np.expm1(meta_model.predict(metas))\n",
    "\n",
    "#use meta model to predict real values\n",
    "test_metas = pd.DataFrame()\n",
    "test_metas['XGB'] = preds_xgb\n",
    "test_metas['Lasso'] = preds_lasso\n",
    "test_metas['EN'] = preds_en\n",
    "meta_preds = np.expm1(meta_model.predict(test_metas))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([123999.57121429, 148226.18459799, 169395.4383644 , ...,\n",
       "       151506.99938035, 123342.80765637, 203991.80340394])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "meta_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([120263.95, 159329.19, 184361.39, ..., 162071.81, 118952.3 ,\n",
       "       220300.75], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([119437.66227121, 153587.32165746, 181705.92738773, ...,\n",
       "       159642.19986078, 121074.96684393, 217725.79308434])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([120122.53345675, 150582.29517558, 180728.72911449, ...,\n",
       "       157919.61338093, 119478.1810153 , 220779.20455367])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([119941.38295099, 154499.60144435, 182265.34904241, ...,\n",
       "       159877.87524724, 119835.14824474, 219601.91587934])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = (preds_xgb + preds_lasso + preds_en)/3\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- EXPORT PREDICTIONS ----------\n",
    "out_preds = pd.DataFrame()\n",
    "out_preds['Id'] = test['Id']\n",
    "out_preds['SalePrice'] = meta_preds\n",
    "out_preds.to_csv('output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
